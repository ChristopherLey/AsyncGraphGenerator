{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb6b8c8b545ac7c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:33:30.085810561Z",
     "start_time": "2024-01-06T18:33:28.578353391Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from tqdm import trange\n",
    "from tqdm.contrib.logging import logging_redirect_tqdm\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from torchmetrics import MeanSquaredError\n",
    "\n",
    "from AGG.extended_typing import ContinuousTimeGraphSample\n",
    "from AGG.graph_dataset import GraphDataset\n",
    "from AGG.utils import FeedForward\n",
    "from AGG.utils import Time2Vec\n",
    "from AGG.transformer_model import SelfAttentionBlock, CrossAttentionBlock\n",
    "from torch.utils.data import DataLoader\n",
    "from AGG.extended_typing import collate_graph_samples\n",
    "from Datasets.data_tools import random_index\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "LOG = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")\n",
    "experiment = datetime.now().strftime(\"%d-%m_%H:%M:%S\")\n",
    "print(f'Log for {experiment=}')\n",
    "\n",
    "\n",
    "class AGG(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 feature_dim: int,\n",
    "                 num_heads: int,\n",
    "                 time_embedding_dim: int,\n",
    "                 num_layers: int,\n",
    "                 attention_drop: float = 0.2,\n",
    "                 dropout: float = 0.2,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.feature_projection = nn.Linear(input_dim, feature_dim)\n",
    "        self.node_feature_dim = feature_dim + time_embedding_dim\n",
    "        self.query_dim = time_embedding_dim\n",
    "        self.time_embed = Time2Vec(time_embedding_dim)\n",
    "        self.agg_layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.agg_layers.append(\n",
    "                SelfAttentionBlock(\n",
    "                    embed_dim=self.node_feature_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    dropout=attention_drop,\n",
    "                    batch_first=True,\n",
    "                )\n",
    "            )\n",
    "        self.cross_attention = CrossAttentionBlock(\n",
    "            target_dim=self.query_dim,\n",
    "            source_dim=self.node_feature_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=attention_drop,\n",
    "        )\n",
    "        self.head = FeedForward(\n",
    "            input_size=self.query_dim,\n",
    "            hidden_dim=self.query_dim * num_heads,\n",
    "            output_size=input_dim,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, graph: ContinuousTimeGraphSample, device: torch.device = \"cpu\") -> Tuple[Tensor, list]:\n",
    "        features = self.feature_projection(graph.node_features.unsqueeze(-1).to(device))\n",
    "        time_encode = self.time_embed(graph.time.unsqueeze(-1).to(device))\n",
    "        source_list = [features, time_encode]\n",
    "        source = torch.cat(\n",
    "            source_list,\n",
    "            dim=-1,\n",
    "        )\n",
    "        query_list = [\n",
    "            self.time_embed(graph.target.time.unsqueeze(-1).to(device)),\n",
    "        ]\n",
    "        target = torch.cat(\n",
    "            query_list,\n",
    "            dim=-1,\n",
    "        )\n",
    "        key_padding_mask = graph.key_padding_mask.to(device)\n",
    "        attn_mask = graph.attention_mask.to(device)\n",
    "        hidden = source\n",
    "        if torch.any(torch.isnan(source)):\n",
    "            print(source)\n",
    "        if torch.any(torch.isnan(target)):\n",
    "            print(target)\n",
    "        total_attention = []\n",
    "        for agg_layer in self.agg_layers:\n",
    "            hidden, attention_weights = agg_layer(hidden, attn_mask, key_padding_mask)\n",
    "            total_attention.append(attention_weights)\n",
    "        y_hat, attention_weights = self.cross_attention(\n",
    "            target, hidden, key_padding_mask\n",
    "        )\n",
    "        total_attention.append(attention_weights)\n",
    "        y_hat = self.head(y_hat)\n",
    "        y_hat = y_hat.squeeze(-1)\n",
    "        return y_hat, total_attention\n",
    "\n",
    "\n",
    "class SinusoidDataset(GraphDataset):\n",
    "    def __init__(self, context_length: int | None = None):\n",
    "        fs = 1000\n",
    "        t = np.arange(0, 10, 1 / fs)\n",
    "        f = 10\n",
    "        x = np.sin(2 * np.pi * f * t)\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        removed, remainder = random_index(x.shape[0], 0.95)\n",
    "        self.training_samples = x[remainder]\n",
    "        self.training_samples_t = t[remainder]\n",
    "        _, target_index = random_index(removed.shape[0], 0.95)\n",
    "        self.target_samples = x[removed[target_index]]\n",
    "        self.target_samples_t = t[removed[target_index]]\n",
    "        if context_length is None:\n",
    "            context_length = self.training_samples.shape[0]\n",
    "        self.dataset = self.generate_data(context_length)\n",
    "\n",
    "    def generate_data(self, context_length: int) -> list:\n",
    "        graph_dataset = []\n",
    "        for i in trange(0, self.training_samples.shape[0] - context_length + 1):\n",
    "            time = self.training_samples_t[i: i + context_length]\n",
    "            tau = time\n",
    "            target_times = self.target_samples_t[\n",
    "                (self.target_samples_t >= time[0])\n",
    "                & (self.target_samples_t <= time[-1])\n",
    "                ]\n",
    "            target_samples_masked = self.target_samples[\n",
    "                (self.target_samples_t >= time[0])\n",
    "                & (self.target_samples_t <= time[-1])\n",
    "                ]\n",
    "            for j in trange(target_times.shape[0]):\n",
    "                target_time = target_times[j]\n",
    "                graph_dataset.append({\n",
    "                    \"node_features\": self.training_samples[i: i + context_length].tolist(),\n",
    "                    \"time\": tau.tolist(),\n",
    "                    'key_padding_mask': (\n",
    "                            np.zeros_like(time) != 0\n",
    "                        ).tolist(),\n",
    "                    \"target\": {\n",
    "                        \"features\": [target_samples_masked[j].tolist(), ],\n",
    "                        \"time\": [target_time.tolist(), ],\n",
    "                    }\n",
    "                })\n",
    "        return graph_dataset\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> ContinuousTimeGraphSample:\n",
    "        graph = self.graph_transform(self.dataset[idx])\n",
    "        return graph\n",
    "\n",
    "\n",
    "model = AGG(\n",
    "    input_dim=1,\n",
    "    feature_dim=4,\n",
    "    num_heads=2,\n",
    "    time_embedding_dim=4,\n",
    "    num_layers=1,\n",
    "    attention_drop=0.0,\n",
    "    dropout=0.0,\n",
    ")\n",
    "sinusoid_dataset = SinusoidDataset(context_length=100)\n",
    "\n",
    "sinusoid_train_dataloader = DataLoader(\n",
    "    sinusoid_dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=8,\n",
    "    collate_fn=collate_graph_samples,\n",
    ")\n",
    "\n",
    "sinusoid_val_dataloader = DataLoader(\n",
    "    sinusoid_dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=8,\n",
    "    collate_fn=collate_graph_samples,\n",
    ")\n",
    "print(f\"Number of training samples: {len(sinusoid_dataset)}\")\n",
    "print(f\"Model summary: {model}\")\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-06T18:34:44.700754632Z",
     "start_time": "2024-01-06T18:34:42.905183830Z"
    }
   },
   "id": "initial_id",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_RMSE = MeanSquaredError(squared=False).to(device)\n",
    "val_RMSE = MeanSquaredError(squared=False).to(device)\n",
    "epochs = 1000\n",
    "total_train = np.inf\n",
    "total_val = np.inf\n",
    "lowest_loss = np.inf\n",
    "with logging_redirect_tqdm():\n",
    "    prog_bar = trange(epochs, leave=True)\n",
    "    for epoch in prog_bar:\n",
    "        model.train()\n",
    "        for graph_samples in sinusoid_train_dataloader:\n",
    "            y_hat, total_attention = model(graph_samples, device)\n",
    "            loss = mse_loss(y_hat, graph_samples.target.features.to(device))\n",
    "            rmse = train_RMSE(y_hat, graph_samples.target.features.to(device))\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimiser.step()\n",
    "            prog_bar.set_description(f\"current loss: {loss.item()}, train_rmse {total_train:.4f}, val_rmse {total_val:.4f}\", refresh=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            total_train = train_RMSE.compute()\n",
    "            prog_bar.set_description(f\"current loss: {loss.item()}, train_rmse {total_train:.4f}, val_rmse {total_val:.4f}\", refresh=True)\n",
    "            model.eval()\n",
    "            for graph_samples in sinusoid_val_dataloader:\n",
    "                y_hat, total_attention = model(graph_samples, device)\n",
    "                loss = mse_loss(y_hat, graph_samples.target.features.to(device))\n",
    "                rmse = val_RMSE(y_hat, graph_samples.target.features.to(device))\n",
    "            total_val = val_RMSE.compute()\n",
    "            prog_bar.set_description(f\"current loss: {loss.item()}, train_rmse {total_train:.4f}, val_rmse {total_val:.4f}\",\n",
    "                                     refresh=True)\n",
    "            if total_val < lowest_loss:\n",
    "                torch.save(\n",
    "                    model.state_dict(), f\"./best_model_{experiment}.mdl\"\n",
    "                )\n",
    "                lowest_loss = total_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T21:49:44.193976026Z",
     "start_time": "2024-01-06T18:35:14.830755132Z"
    }
   },
   "id": "e195f2ac2df4aa1e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model.load_state_dict(torch.load(f\"best_model_{experiment}.mdl\"))\n",
    "predictions = []\n",
    "predict_time = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for graph_samples in sinusoid_val_dataloader:\n",
    "        y_hat, total_attention = model(graph_samples, device)\n",
    "        predictions += y_hat.flatten().tolist()\n",
    "        predict_time += graph_samples.target.time.flatten().tolist()\n",
    "input = graph_samples.node_features.flatten().tolist()\n",
    "input_t = graph_samples.time.flatten().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T21:49:50.929098824Z",
     "start_time": "2024-01-06T21:49:44.153272706Z"
    }
   },
   "id": "1f23cf6b03928dd8",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "shifted_t_input = sinusoid_dataset.t.max() - np.array(input_t)*5.0\n",
    "shifted_t_predict = sinusoid_dataset.t.max() - np.array(predict_time)*5.0\n",
    "plt.plot(sinusoid_dataset.t, sinusoid_dataset.x, label=\"Continuous Signal\")\n",
    "plt.plot(shifted_t_input, np.array(input), 'bo', label=\"Training Inputs\")\n",
    "plt.plot(sinusoid_dataset.target_samples_t, sinusoid_dataset.target_samples, 'rx', label=\"Target Samples\")\n",
    "plt.plot(shifted_t_predict, np.array(predictions), 'g+', label=\"Predictions\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T21:49:51.173621192Z",
     "start_time": "2024-01-06T21:49:50.938798080Z"
    }
   },
   "id": "84a185c04da431c3",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model.time_embed.linear.weight/(torch.pi*2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T21:49:51.221047108Z",
     "start_time": "2024-01-06T21:49:51.174113198Z"
    }
   },
   "id": "76b59293703c311e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model.time_embed.linear.bias"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T21:49:51.221461828Z",
     "start_time": "2024-01-06T21:49:51.177837871Z"
    }
   },
   "id": "b2fc966c3f2c5283",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "t = torch.linspace(0, 5, 1000).to(device)\n",
    "t = t.unsqueeze(-1)\n",
    "tau = model.time_embed(t)*5.0\n",
    "plt.plot(tau.detach().cpu().numpy())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T21:49:51.303538904Z",
     "start_time": "2024-01-06T21:49:51.191567042Z"
    }
   },
   "id": "98d625db2f98e983",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-06T18:33:58.451076159Z"
    }
   },
   "id": "18f6469f5a3665dc",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
